{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b7af9ec8fca084",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hybrid Search: dense and sparse vectors\n",
    "\n",
    "LlamaIndex integration with Qdrant supports sparse embeddings as well. From the user perspective, it doesn't change much, as they interact through the same interface. Since sparse and dense vectors work best in different setups, it makes sense to combine them if we want to have the best of both worlds. There are, however, some parameters we can control.\n",
    "\n",
    "Let's again start with recreating our pipeline, but this time we will use the other collection that has sparse vectors as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660547c536bbfa43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f2eda9a0c435d8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fc9049413d2075",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d046b979c334b939a1b2b0912825d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f88c3b6e904411b53c64e4b4896f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f9b2428d604f89b118873b512bddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370916b26f104a8caa0e386e764c6eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2af846134ca4fb484ae7e137623886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49439d5ac7284e7f90bf3b9829b93837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4a722fe96e48fcb78f068943ca9eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/417 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ba961a66b4b9e98dd3b975d56fa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f745fd45ad45969debbc2cb779d8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe240ba7b3374edfae13d6631e7c4af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a5bebf9534213a7def9886702c63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59cb36d095b41e681b83f5caf28ec98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "import os\n",
    "\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")\n",
    "vector_store_hybrid = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"hacker-news-hybrid\",\n",
    "    enable_hybrid=True,\n",
    "    batch_size=20,  # this is important for the ingestion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdcf928f564b071",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store_hybrid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa7483e19c702",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Differences between sparse and dense vectors\n",
    "\n",
    "Sparse vectors are usually used in high-dimensional spaces, where the majority of the elements are zero. A single dimension represents a single word, so the dimensionality of the space is equal to the size of the vocabulary, with just a few non-zero values. \n",
    "\n",
    "There are various ways to create sparse vectors, but the most common one is to use the TF-IDF or BM25 representation. It's a simple and effective way to represent the importance of words in a document and in many cases create a solid baseline for the search.\n",
    "\n",
    "LlamaIndex uses SPLADE by default, which is based on transformers, similar to dense embedding models. **The main advantage of using sparse vectors is that they overcome the problem of vocabulary mismatch**. If a word is not present in the vocabulary of the dense embedding model, we can still represent it using the sparse vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd696863d4c0144",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using sparse vectors only\n",
    "\n",
    "Before we dive into the hybrid search, let's see what might be achieved by using sparse vectors alone. We already know the nodes retrieved by dense vectors so it makes sense to compare the results returned by both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b724350a8f0a9fbd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.core.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "sparse_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.SPARSE,\n",
    "    sparse_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4762c0e9b8fb0231",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "Disclosure: I&#x27;ve never done it.  But I looked at some CUDA code from Leela Chess Zero and it made reasonable sense.  It&#x27;s just C++ with some slight changes.  The GPU architecture is a little bit quirky but not that complicated either.  Plus there are libraries like pytorch that handle most of the GPU stuff for you.<p>I would say ML concepts and algorithms are way more complicated than GPU programming per se.  The fast.ai lectures were pretty understandable when I watched some of them a few years ago, but attention wasn&#x27;t yet invented, and it was pretty obvious that it would take a fair amount of trial and error to become skilful at writing simple recognizers.\n",
      "\n",
      "2 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "It would also mean learning Julia, but you can write GPU kernels in Julia and then compile for NVidia CUDA, AMD ROCm or IBM oneAPI.<p><a href=\"https:&#x2F;&#x2F;juliagpu.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;juliagpu.org&#x2F;</a><p>I&#x27;ve written CUDA kernels and I knew nothing about it going in.\n",
      "\n",
      "While I am a fan of Julia and its GPU module, using such an easy environment will really limit what you are able to learn. NVIDIA provides some great optimization tools (NSight Systems and NSight Compute) which help you optimize your kernel execution (fuse kernels, hide latency, use execution graphs) and CUDA code (take advantage of memory layout, use warp intrinsics, maximize throughput). These tools map to C++&#x2F;CUDA source code and let you rapidly address bottlenecks - most of which may be on the host side.\n",
      "\n",
      "3 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "For CUDA specifically, there is a fairly large set of sample code that used to be installed when you installed CUDA.  But now I think it’s on the Nvidia GitHub page; you’ve got to download it yourself.<p>The Nvidia dev blog has some easy to follow tutorials, but they don’t get very complicated.<p>Nvidia also has a learning platform which offers fairly decent courses at a cost.  You get a certificate for finishing.<p>You’ll find some books out there with good reputations.  Ultimately, this is an area that leans heavily toward paying money for good quality learning materials.\n",
      "\n",
      "4 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "It would also mean learning Julia, but you can write GPU kernels in Julia and then compile for NVidia CUDA, AMD ROCm or IBM oneAPI.<p><a href=\"https:&#x2F;&#x2F;juliagpu.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;juliagpu.org&#x2F;</a><p>I&#x27;ve written CUDA kernels and I knew nothing about it going in.\n",
      "\n",
      "5 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = sparse_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05f74509f13f9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hybrid search\n",
    "\n",
    "There are some specific use cases in which we may prefer to use just the sparse vectors. But both methods may complement each other and we usually need to find the sweet spot. The `VectorIndexRetriever` class allows us to control the parameters of the search. We can set the `sparse_top_k` and `similarity_top_k` parameters to control the number of results returned by each method. We can also set the `alpha` parameters to control the importance of each method (`0.0` = sparse, `1.0` = dense vectors only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa7191e7ad214de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hybrid_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.HYBRID,\n",
    "    sparse_top_k=5,\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbf546068405a4d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "Disclosure: I&#x27;ve never done it.  But I looked at some CUDA code from Leela Chess Zero and it made reasonable sense.  It&#x27;s just C++ with some slight changes.  The GPU architecture is a little bit quirky but not that complicated either.  Plus there are libraries like pytorch that handle most of the GPU stuff for you.<p>I would say ML concepts and algorithms are way more complicated than GPU programming per se.  The fast.ai lectures were pretty understandable when I watched some of them a few years ago, but attention wasn&#x27;t yet invented, and it was pretty obvious that it would take a fair amount of trial and error to become skilful at writing simple recognizers.\n",
      "\n",
      "2 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "It would also mean learning Julia, but you can write GPU kernels in Julia and then compile for NVidia CUDA, AMD ROCm or IBM oneAPI.<p><a href=\"https:&#x2F;&#x2F;juliagpu.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;juliagpu.org&#x2F;</a><p>I&#x27;ve written CUDA kernels and I knew nothing about it going in.\n",
      "\n",
      "While I am a fan of Julia and its GPU module, using such an easy environment will really limit what you are able to learn. NVIDIA provides some great optimization tools (NSight Systems and NSight Compute) which help you optimize your kernel execution (fuse kernels, hide latency, use execution graphs) and CUDA code (take advantage of memory layout, use warp intrinsics, maximize throughput). These tools map to C++&#x2F;CUDA source code and let you rapidly address bottlenecks - most of which may be on the host side.\n",
      "\n",
      "3 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "For CUDA specifically, there is a fairly large set of sample code that used to be installed when you installed CUDA.  But now I think it’s on the Nvidia GitHub page; you’ve got to download it yourself.<p>The Nvidia dev blog has some easy to follow tutorials, but they don’t get very complicated.<p>Nvidia also has a learning platform which offers fairly decent courses at a cost.  You get a certificate for finishing.<p>You’ll find some books out there with good reputations.  Ultimately, this is an area that leans heavily toward paying money for good quality learning materials.\n",
      "\n",
      "4 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "It would also mean learning Julia, but you can write GPU kernels in Julia and then compile for NVidia CUDA, AMD ROCm or IBM oneAPI.<p><a href=\"https:&#x2F;&#x2F;juliagpu.org&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;juliagpu.org&#x2F;</a><p>I&#x27;ve written CUDA kernels and I knew nothing about it going in.\n",
      "\n",
      "5 Ask HN: What would you look for in a platform to learn programming?\n",
      "\n",
      "Hey everyone!<p>I&#x27;m curious, what does the perfect programming education platform look like to you?<p>I&#x27;m an experienced developer, but I really think that the current options for learning programming could be a lot better. I know that there are platforms like CodeCademy and places to watch video courses like YouTube and Udemy. There are also so many scammy &quot;learn to code&quot; sites (CodeFinity).<p>The pattern I notice is that platforms like CodeCademy are web-apps and are very career-path-oriented (i.e. get certifications). I personally think that having a platform which was a desktop app would be a better solution. Rather than focusing on career-tracks, you could follow courses to build a specific project using an integrated IDE, 100% on your machine.<p>How important are career-tracks and certifications to you? Or, would you rather just learn to build a specific project on your own machine all in one application?<p>Basically, a native desktop platform to learn programming by actually building projects on your own machine. No BS.\n",
      "\n",
      "There are three distinct things, which you probably need to keep separate:  learning to <i>program</i>, learning to program in a particular <i>style&#x2F;approach&#x2F;methodology</i>, and learning to program in a particular <i>language</i>.<p>For teaching programming in a language, you just need some kind of guide to the language plus an IDE.<p>For teaching programming in a style (FP, say), some kind of guide to FP, plus some IDEs for some FP languages, plus guides to those languages.<p>For teaching programming <i>at all</i>... I&#x27;m not sure there&#x27;s a way to teach what programming is without teaching at least one of FP&#x2F;OO&#x2F;structured&#x2F;some other approach.  But if you do, then you&#x27;re not teaching programming, you&#x27;re teaching programming by that approach - unless you teach them all.<p>Maybe the best you could do is say that programming is giving instructions to the computer in a formal language.  So you create an IDE (plus guide) to some synthetic thing that lets you program, but has no bias for any particular approach (allows them all, or does none of the above).  For that, it probably needs to be fairly simple - something for learning, not something for real work.<p>Note that BASIC and Pascal started with this approach.\n",
      "\n",
      "Those are some solid points that I didn&#x27;t consider. Thank you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes = hybrid_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1290259a827c3f77",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ask HN: What would you look for in a platform to learn programming?\n",
      "\n",
      "Hey everyone!<p>I&#x27;m curious, what does the perfect programming education platform look like to you?<p>I&#x27;m an experienced developer, but I really think that the current options for learning programming could be a lot better. I know that there are platforms like CodeCademy and places to watch video courses like YouTube and Udemy. There are also so many scammy &quot;learn to code&quot; sites (CodeFinity).<p>The pattern I notice is that platforms like CodeCademy are web-apps and are very career-path-oriented (i.e. get certifications). I personally think that having a platform which was a desktop app would be a better solution. Rather than focusing on career-tracks, you could follow courses to build a specific project using an integrated IDE, 100% on your machine.<p>How important are career-tracks and certifications to you? Or, would you rather just learn to build a specific project on your own machine all in one application?<p>Basically, a native desktop platform to learn programming by actually building projects on your own machine. No BS.\n",
      "\n",
      "There are three distinct things, which you probably need to keep separate:  learning to <i>program</i>, learning to program in a particular <i>style&#x2F;approach&#x2F;methodology</i>, and learning to program in a particular <i>language</i>.<p>For teaching programming in a language, you just need some kind of guide to the language plus an IDE.<p>For teaching programming in a style (FP, say), some kind of guide to FP, plus some IDEs for some FP languages, plus guides to those languages.<p>For teaching programming <i>at all</i>... I&#x27;m not sure there&#x27;s a way to teach what programming is without teaching at least one of FP&#x2F;OO&#x2F;structured&#x2F;some other approach.  But if you do, then you&#x27;re not teaching programming, you&#x27;re teaching programming by that approach - unless you teach them all.<p>Maybe the best you could do is say that programming is giving instructions to the computer in a formal language.  So you create an IDE (plus guide) to some synthetic thing that lets you program, but has no bias for any particular approach (allows them all, or does none of the above).  For that, it probably needs to be fairly simple - something for learning, not something for real work.<p>Note that BASIC and Pascal started with this approach.\n",
      "\n",
      "Those are some solid points that I didn&#x27;t consider. Thank you.\n",
      "\n",
      "2 Ask HN: What would you look for in a platform to learn programming?\n",
      "\n",
      "Hey everyone!<p>I&#x27;m curious, what does the perfect programming education platform look like to you?<p>I&#x27;m an experienced developer, but I really think that the current options for learning programming could be a lot better. I know that there are platforms like CodeCademy and places to watch video courses like YouTube and Udemy. There are also so many scammy &quot;learn to code&quot; sites (CodeFinity).<p>The pattern I notice is that platforms like CodeCademy are web-apps and are very career-path-oriented (i.e. get certifications). I personally think that having a platform which was a desktop app would be a better solution. Rather than focusing on career-tracks, you could follow courses to build a specific project using an integrated IDE, 100% on your machine.<p>How important are career-tracks and certifications to you? Or, would you rather just learn to build a specific project on your own machine all in one application?<p>Basically, a native desktop platform to learn programming by actually building projects on your own machine. No BS.\n",
      "\n",
      "There are three distinct things, which you probably need to keep separate:  learning to <i>program</i>, learning to program in a particular <i>style&#x2F;approach&#x2F;methodology</i>, and learning to program in a particular <i>language</i>.<p>For teaching programming in a language, you just need some kind of guide to the language plus an IDE.<p>For teaching programming in a style (FP, say), some kind of guide to FP, plus some IDEs for some FP languages, plus guides to those languages.<p>For teaching programming <i>at all</i>... I&#x27;m not sure there&#x27;s a way to teach what programming is without teaching at least one of FP&#x2F;OO&#x2F;structured&#x2F;some other approach.  But if you do, then you&#x27;re not teaching programming, you&#x27;re teaching programming by that approach - unless you teach them all.<p>Maybe the best you could do is say that programming is giving instructions to the computer in a formal language.  So you create an IDE (plus guide) to some synthetic thing that lets you program, but has no bias for any particular approach (allows them all, or does none of the above).  For that, it probably needs to be fairly simple - something for learning, not something for real work.<p>Note that BASIC and Pascal started with this approach.\n",
      "\n",
      "3 Ask HN: Programming Courses for Experienced Coders?\n",
      "\n",
      "Lately I&#x27;ve been learning Elixir. Many of the popular resources seem beginner-focused, which feels a bit tedious when you&#x27;ve been coding for over a decade. Are there any popular programming books or courses for more experienced coders?\n",
      "\n",
      "Aside from raw theory, the best thing you can do is try to translate a project you have, maybe a toy project of reasonable complexity, and rewrite it idiomatically in the new language. Use all the preferred methods, semantics, and modeling tools of the target language. Use the language&#x27;s docs and X in Y Minutes page.\n",
      "\n",
      "But &quot;which methods, semantics, and modeling tools are preferred&quot; is probably what you&#x27;re trying to learn.\n",
      "\n",
      "Unfortunately, that&#x27;s what language docs are for. Like I said, you can get some theory. If you&#x27;re learning functional programming, you can find books on lambda calculus and category theory and more. But ultimately you have to learn how to build good software, and there are scant few books about that out there. In the functional world, I know of two and they&#x27;re both in Scheme. So the best approach tends to be feet-first into the fire using the language&#x27;s docs, and hopefully the creator(s) has documents explaining theory and practice.\n",
      "\n",
      "4 Ask HN: Resources for kids/teens to learn programming\n",
      "\n",
      "My friend is seeking online courses or resources for his 12-year-old child to learn programming skills.\n",
      "\n",
      "I learned programming through a mixture of Scratch and code.org. Once I &quot;graduated&quot; from those websites, I learned my first professional programming language using W3Schools.<p>I wouldn&#x27;t recommend signing up for W3Schools, but the free content is a good enough primer for beginners. (Some of the examples are not idiomatic, though.)<p>I hope that helps :)\n",
      "\n",
      "5 Ask HN: Best way to learn GPU programming?\n",
      "\n",
      "I&#x27;d like to learn GPU programming but I&#x27;m having difficulty finding high-quality resources. I tried a class at coursera and was severely disappointed by both quality and content.<p>What are the best resources for learning things like GPU architecture, CUDA, Triton, etc?<p>My goal is to do be able to do something like take a description of Flash Attention and implement it from scratch, or optimize existing CUDA code.\n",
      "\n",
      "Disclosure: I&#x27;ve never done it.  But I looked at some CUDA code from Leela Chess Zero and it made reasonable sense.  It&#x27;s just C++ with some slight changes.  The GPU architecture is a little bit quirky but not that complicated either.  Plus there are libraries like pytorch that handle most of the GPU stuff for you.<p>I would say ML concepts and algorithms are way more complicated than GPU programming per se.  The fast.ai lectures were pretty understandable when I watched some of them a few years ago, but attention wasn&#x27;t yet invented, and it was pretty obvious that it would take a fair amount of trial and error to become skilful at writing simple recognizers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We shouldn't be modifying the alpha parameter after the retriever has been created\n",
    "# but that's the easiest way to show the effect of the parameter\n",
    "hybrid_retriever._alpha = 0.9\n",
    "\n",
    "nodes = hybrid_retriever.retrieve(\"What is the best way to learn programming?\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af4ef3d86d61ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
